airbnb<-read.csv('airbnb-listings.csv',sep = ';')
airbnb<-read.csv('airbnb-listings.csv',sep = ';')
library(dplyr)
# 1. Cargamos el dataset.
# Importante: usamos sep=',' porque tu archivo usa comas.
airbnb <- read.csv('airbnb.csv', sep = ',')
airbnb<-read.csv('airbnb-listings.csv',sep = ';')
airbnb<-read.csv('airbnb-listings.csv',sep = ';')
airbnb<-read.csv('airbnb-listings.csv',sep = ';')
library(dplyr)
# 1. Cargamos el dataset.
# Importante: usamos sep=',' porque tu archivo usa comas.
airbnb <- read.csv('airbnb.csv', sep = ',')
# 2. Creamos la columna Square.Meters (metros cuadrados)
# Factor de conversión: 1 sq feet = 0.092903 m2
df_madrid <- df_madrid %>%
mutate(Square.Meters = Square.Feet * 0.092903)
library(dplyr)
# 1. Cargamos el dataset.
# Importante: usamos sep=',' porque tu archivo usa comas.
airbnb <- read.csv('airbnb.csv', sep = ',')
# 2. Creamos la columna Square.Meters (metros cuadrados)
# Factor de conversión: 1 sq feet = 0.092903 m2
df_madrid <- df_madrid %>%
mutate(Square.Meters = Square.Feet * 0.092903)
# 2. Creamos la columna Square.Meters (metros cuadrados)
# Factor de conversión: 1 sq feet = 0.092903 m2
df_madrid <- df_madrid %>%
mutate(Square.Meters = Square.Feet * 0.092903)
# 2. Creamos la columna Square.Meters (metros cuadrados)
# Factor de conversión: 1 sq feet = 0.092903 m2
df_madrid <- df_madrid %>%
mutate(Square.Meters = Square.Feet * 0.092903)
airbnb<-read.csv('airbnb-listings.csv',sep = ';')
library(dplyr)
# 1. Cargamos el dataset.
# Importante: usamos sep=',' porque tu archivo usa comas.
airbnb <- read.csv('airbnb.csv', sep = ',')
library(dplyr)
# 1. Cargamos el dataset.
# Importante: usamos sep=',' porque tu archivo usa comas.
airbnb <- read.csv('airbnb.csv', sep = ',')
# Filtramos por tipo de habitación y seleccionamos columnas
df_madrid <- airbnb %>%
filter(Room.Type == "Entire home/apt",
Neighbourhood.Cleansed != "") %>%
select(
Neighbourhood = Neighbourhood.Cleansed, # Renombramos para facilitar el uso
Accommodates,
Bathrooms,
Bedrooms,
Beds,
Price,
Square.Feet,
Review.Scores.Rating
)
# 2. Creamos la columna Square.Meters (metros cuadrados)
# Factor de conversión: 1 sq feet = 0.092903 m2
df_madrid <- df_madrid %>%
mutate(Square.Meters = Square.Feet * 0.092903)
# 3. ¿Qué porcentaje de Square.Meters son NA?
total_filas <- nrow(df_madrid)
nas_iniciales <- sum(is.na(df_madrid$Square.Meters))
pct_na <- (nas_iniciales / total_filas) * 100
cat("Porcentaje de NAs iniciales:", round(pct_na, 2), "%\n")
# 4. ¿Qué porcentaje de los que SÍ tienen datos son 0?
# Los ceros suelen ser errores de carga de datos.
con_datos <- df_madrid %>% filter(!is.na(Square.Meters))
pct_ceros <- (sum(con_datos$Square.Meters == 0) / nrow(con_datos)) * 100
cat("Porcentaje de valores 0 m2:", round(pct_ceros, 2), "%\n")
# 5. Convertimos los 0 en NA
df_madrid$Square.Meters[df_madrid$Square.Meters == 0] <- NA
# 6. Histograma de metros cuadrados
# Usamos un número alto de 'breaks' para ver bien el detalle cerca del cero
hist(df_madrid$Square.Meters,
breaks = 60,
main = "Distribución de Metros Cuadrados",
xlab = "Metros Cuadrados (m2)",
col = "steelblue",
border = "white")
# 7. Asignar NA a los menores de 20 m2
df_madrid$Square.Meters[df_madrid$Square.Meters < 20] <- NA
# Verificamos cuántos NAs tenemos ahora
sum(is.na(df_madrid$Square.Meters))
# 8. Eliminar registros de barrios que NO tienen ningún dato de metros cuadrados
# Primero identificamos qué barrios tienen algún dato (no NA)
barrios_con_datos <- df_madrid %>%
group_by(Neighbourhood) %>%
summarise(total_datos = sum(!is.na(Square.Meters))) %>%
filter(total_datos > 0) %>%
pull(Neighbourhood)
# Filtramos el dataset para quedarnos solo con esos barrios
df_madrid <- df_madrid %>%
filter(Neighbourhood %in% barrios_con_datos)
# 9. Test ANOVA
# Usamos Square.Meters en función del Barrio
anova_m2 <- aov(Square.Meters ~ Neighbourhood, data = df_madrid)
# Vemos el resultado
summary(anova_m2)
# 10. Aplicamos el test de Tukey
tukey_test <- TukeyHSD(anova_m2)
# Esto genera una tabla enorme con comparaciones como "Centro-Retiro"
# El p-valor (p adj) nos indica la similitud.
# Si p > 0.05 -> Los barrios se parecen mucho en tamaño.
# Si p < 0.05 -> Los barrios son significativamente diferentes.
head(tukey_test$Neighbourhood)
# 11. Crear matriz de distancias basada en p-valores
# Primero extraemos los nombres de los barrios únicos
barrios <- levels(as.factor(df_madrid$Neighbourhood))
n <- length(barrios)
# Creamos una matriz vacía llena de 1s (distancia máxima)
dist_matrix <- matrix(0, nrow = n, ncol = n)
rownames(dist_matrix) <- barrios
colnames(dist_matrix) <- barrios
# Rellenamos con los p-valores del test de Tukey
# Nota: Este paso asume que comparamos todos contra todos
# Para simplificar la práctica, solemos usar las medias por barrio:
medias_barrios <- df_madrid %>%
group_by(Neighbourhood) %>%
summarise(media = mean(Square.Meters, na.rm = TRUE))
# Una forma más directa para el dendrograma en clase suele ser:
distancias <- dist(medias_barrios$media)
hc <- hclust(distancias, method = "ward.D2")
hc$labels <- medias_barrios$Neighbourhood
# Dibujamos el dendrograma
plot(hc, hang = -1, main = "Dendrograma de Barrios por m2", cex = 0.6)
# PASO A: Dibujar el árbol (Dendrograma)
plot(hc, main = "Dendrograma de barrios", hang = -1)
# PASO B: Dibujar los rectángulos (Punto 10 - Visual)
# Aquí es donde decides si 5 clusters es un buen punto de corte
rect.hclust(hc, k = 5, border = "red")
# PASO C: Crear la columna neighb_id (Punto 11 - Datos)
# Esto es lo que "etiqueta" cada barrio con un número del 1 al 5
grupos <- cutree(hc, k = 5)
# PASO D: Pasar esa información al dataframe principal
df_clusters <- data.frame(
Neighbourhood = medias_barrios$Neighbourhood,
neighb_id = as.factor(grupos)
)
df_madrid <- left_join(df_madrid, df_clusters, by = "Neighbourhood")
# 12. Filtramos solo los que tienen metros cuadrados (para entrenar)
df_con_m2 <- df_madrid %>% filter(!is.na(Square.Meters))
set.seed(123) # Para que siempre nos salgan los mismos números aleatorios
idx <- sample(1:nrow(df_con_m2), nrow(df_con_m2) * 0.7) # 70% entrenamiento
train_data <- df_con_m2[idx, ]
test_data <- df_con_m2[-idx, ]
# 13. Entrenamos el modelo (Regresión Lineal Multiple)
modelo_final <- lm(Square.Meters ~ Accommodates + Bathrooms + Bedrooms + Price + neighb_id,
data = train_data)
# 14. Evaluamos la calidad
resumen <- summary(modelo_final)
print(resumen)
# 15a. Buscamos a qué cluster pertenece el barrio "Sol"
cluster_sol <- df_madrid %>%
filter(Neighbourhood == "Sol") %>%
select(neighb_id) %>%
unique() %>%
pull()
# 15b. Creamos el objeto con los datos del anuncio
# Nota: Incluimos 'Beds' y 'Review.Scores.Rating' porque estaban en el select inicial
anuncio_sol <- data.frame(
Accommodates = 6,
Bathrooms = 1,
Price = 80,
Bedrooms = 3,
Beds = 3,
Review.Scores.Rating = 80,
neighb_id = cluster_sol
)
# 15c. Realizamos la predicción
prediccion_m2 <- predict(modelo_final, newdata = anuncio_sol)
cat("La predicción para el apartamento en Sol es de:", round(prediccion_m2, 2), "m2\n")
# 15d. ¿Cómo varía por cada habitación adicional?
# Miramos el coeficiente del modelo para 'Bedrooms'
coef_habitacion <- coef(modelo_final)["Bedrooms"]
cat("Por cada habitación extra, el modelo estima un aumento de:", round(coef_habitacion, 2), "m2\n")
# --- SOLUCIÓN DE SEGURIDAD PARA EL PASO 16 ---
# 1. Identificamos qué grupos (niveles) "aprendió" realmente el modelo
# (Esto evita el error de 'new levels')
niveles_aprendidos <- levels(modelo_final$xlevels$neighb_id)
# 2. Creamos un vector de predicciones vacío (lleno de NAs)
predicciones_seguras <- rep(NA, nrow(df_madrid))
# 3. Identificamos qué filas de df_madrid tienen un grupo que el modelo conoce
# Y además, nos aseguramos de que no tengan NAs en las otras variables (Precio, Baños, etc.)
filas_predecibles <- df_madrid$neighb_id %in% niveles_aprendidos &
!is.na(df_madrid$Accommodates) &
!is.na(df_madrid$Bathrooms) &
!is.na(df_madrid$Bedrooms) &
!is.na(df_madrid$Price)
# 4. Predecimos SOLO para esas filas
predicciones_seguras[filas_predecibles] <- predict(modelo_final, newdata = df_madrid[filas_predecibles, ])
# 5. Rellenamos los NAs de la columna original Square.Meters
# Solo rellenamos donde originalmente no había dato
indices_a_rellenar <- is.na(df_madrid$Square.Meters)
df_madrid$Square.Meters[indices_a_rellenar] <- predicciones_seguras[indices_a_rellenar]
# 6. ¿Aún quedan NAs? (Por grupos nuevos o datos faltantes en el anuncio)
# Si quedan, usamos la media general para que el dataset sea perfecto
if(sum(is.na(df_madrid$Square.Meters)) > 0) {
media_sustituta <- mean(df_madrid$Square.Meters, na.rm = TRUE)
df_madrid$Square.Meters[is.na(df_madrid$Square.Meters)] <- media_sustituta
}
# 7. Verificación Final
cat("¡Éxito! NAs finales en Square.Meters:", sum(is.na(df_madrid$Square.Meters)), "\n")
niveles_aprendidos <- levels(modelo_final$xlevels$neighb_id)
predicciones_seguras <- rep(NA, nrow(df_madrid))
filas_predecibles <- df_madrid$neighb_id %in% niveles_aprendidos &
!is.na(df_madrid$Accommodates) &
!is.na(df_madrid$Bathrooms) &
!is.na(df_madrid$Bedrooms) &
!is.na(df_madrid$Price)
predicciones_seguras[filas_predecibles] <- predict(modelo_final, newdata = df_madrid[filas_predecibles, ])
indices_a_rellenar <- is.na(df_madrid$Square.Meters)
df_madrid$Square.Meters[indices_a_rellenar] <- predicciones_seguras[indices_a_rellenar]
if(sum(is.na(df_madrid$Square.Meters)) > 0) {
media_sustituta <- mean(df_madrid$Square.Meters, na.rm = TRUE)
df_madrid$Square.Meters[is.na(df_madrid$Square.Meters)] <- media_sustituta
}
cat("NAs finales:", sum(is.na(df_madrid$Square.Meters)), "\n")
library(dplyr)
airbnb <- read.csv('airbnb.csv', sep = ',')
df_madrid <- airbnb %>%
filter(Room.Type == "Entire home/apt",
Neighbourhood.Cleansed != "") %>%
select(
Neighbourhood = Neighbourhood.Cleansed,
Accommodates,
Bathrooms,
Bedrooms,
Beds,
Price,
Square.Feet,
Review.Scores.Rating
)
